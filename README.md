# IIT-Palakkad-Information-Bot

# Introdution

a. Background and context:

This project is about developing a information bot for IIT Palakkad using tensorflow libraries.

b. Problem statement and objectives:

In IIT Palakkad information is spread through out multiple platforms and websites. It often becomes difficult find the required information when needed.
The goal of this project is to unify the data and make it accessible through an interactive chatbot which responds to the user's queries.

c. Significance and motivation:

This project can prove to be useful for people residing in IIT Palakkad and make their life a little better.

# Project Overview

a. Project goals and scope:

The goal of the project is to develop an interactive chatbot using the tensorflow libraries. In all its certainity it should perform these actions properly:
  1. Be able to recieve requests
  2. Process the request by using a trained NLP (Natural Language Processing) model
  3. Predict and classify the request
  4. Give a reasonable response to the request

 b. Project timeline:
 
 The project started in early April, around April 9th, 2024.
 The main code was finshed around April 25th, 2024 and has been in testing since

 c. Project Repository: https://github.com/DhanurvikranthPalla/IIT-Palakkad-Information-Bot

 d. Team members and contributions:
   
   1. [Dhanurvikrath Palla] : [Provided the vision for the project and researched the required libraries. Provided code using documentation from tensorflow]
   2. [Sujit Kumar Choudhary] : [Wrote the code and gathered a small amount of information]
   3. [Akash] : [Gathered the requied data and tested the model for effectiveness]

# Methodology

a. Approach and methodology employed:

The main approach was to use tesorflow libraries. Tensorflow provides small computational AI functions and even pre trained models. But the data we are working with is specific so pre trained models are particularly useless. Therefore, it is more plausible to use NLP functions.

An empty .json file will be created and inside the .json file data will be classified into three categories namely: Tag, Patterns and Responses.
This .json file will be read and fed into a NLP model but before feeding the data into the model, it is pre-processed into sizable tokens and enumerated.

